# -*- coding: utf-8 -*-
"""
Moondream ç‹€æ…‹è¨ºæ–·å·¥å…·
æª¢æŸ¥æ¨¡å‹å®‰è£ã€VRAM ä½¿ç”¨ã€é€£æ¥ç‹€æ…‹
"""

import requests
import subprocess
import json
from typing import Dict, List, Optional


class OllamaDiagnostics:
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url.rstrip("/")
    
    def check_server_status(self) -> bool:
        """æª¢æŸ¥ Ollama æœå‹™æ˜¯å¦é‹è¡Œ"""
        print("ğŸ” æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹...")
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=3)
            if response.status_code == 200:
                print("âœ… Ollama æœå‹™æ­£å¸¸é‹è¡Œ")
                return True
            else:
                print(f"âŒ æœå‹™ç•°å¸¸ (HTTP {response.status_code})")
                return False
        except requests.exceptions.ConnectionError:
            print("âŒ ç„¡æ³•é€£æ¥åˆ° Ollama æœå‹™")
            print("   è«‹åŸ·è¡Œ: ollama serve")
            return False
        except Exception as e:
            print(f"âŒ éŒ¯èª¤: {e}")
            return False
    
    def list_installed_models(self) -> List[Dict]:
        """åˆ—å‡ºå·²å®‰è£çš„æ¨¡å‹"""
        print("\nğŸ“¦ å·²å®‰è£çš„æ¨¡å‹:")
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            data = response.json()
            models = data.get("models", [])
            
            if not models:
                print("   âš ï¸  æ²’æœ‰å·²å®‰è£çš„æ¨¡å‹")
                return []
            
            for model in models:
                name = model.get("name", "unknown")
                size = model.get("size", 0) / (1024**3)  # è½‰ç‚º GB
                modified = model.get("modified_at", "unknown")
                print(f"   - {name} ({size:.2f} GB) | æ›´æ–°: {modified}")
            
            return models
        except Exception as e:
            print(f"   âŒ ç„¡æ³•å–å¾—æ¨¡å‹åˆ—è¡¨: {e}")
            return []
    
    def check_running_models(self) -> List[Dict]:
        """æª¢æŸ¥ç•¶å‰é‹è¡Œä¸­çš„æ¨¡å‹"""
        print("\nğŸš€ ç•¶å‰é‹è¡Œä¸­çš„æ¨¡å‹:")
        try:
            response = requests.get(f"{self.base_url}/api/ps", timeout=5)
            data = response.json()
            models = data.get("models", [])
            
            if not models:
                print("   âš ï¸  æ²’æœ‰æ¨¡å‹æ­£åœ¨é‹è¡Œ")
                return []
            
            for model in models:
                name = model.get("name", "unknown")
                size = model.get("size", 0) / (1024**3)
                size_vram = model.get("size_vram", 0) / (1024**3)
                print(f"   - {name}")
                print(f"     ç¸½å¤§å°: {size:.2f} GB | VRAM ä½”ç”¨: {size_vram:.2f} GB")
            
            return models
        except Exception as e:
            print(f"   âŒ ç„¡æ³•å–å¾—é‹è¡Œç‹€æ…‹: {e}")
            return []
    
    def check_moondream_installation(self, models: List[Dict]) -> bool:
        """æª¢æŸ¥ Moondream æ˜¯å¦å·²å®‰è£"""
        print("\nğŸŒ™ æª¢æŸ¥ Moondream å®‰è£ç‹€æ…‹:")
        moondream_found = any("moondream" in m.get("name", "").lower() for m in models)
        
        if moondream_found:
            print("   âœ… Moondream å·²å®‰è£")
            return True
        else:
            print("   âŒ Moondream æœªå®‰è£")
            print("   è«‹åŸ·è¡Œ: ollama pull moondream")
            return False
    
    def test_moondream_inference(self) -> bool:
        """æ¸¬è©¦ Moondream æ¨ç†ï¼ˆç„¡åœ–ç‰‡æ¸¬è©¦ï¼‰"""
        print("\nğŸ§ª æ¸¬è©¦ Moondream æ¨ç†èƒ½åŠ›...")
        try:
            payload = {
                "model": "moondream",
                "prompt": "Test connection. Reply with 'OK'.",
                "stream": False,
                "keep_alive": "1m",  # ä¿æŒ 1 åˆ†é˜ä»¥ä¾¿å¾ŒçºŒæ¸¬è©¦
                "options": {
                    "num_predict": 10
                }
            }
            
            print("   â³ ç­‰å¾…æ¨¡å‹è¼‰å…¥ï¼ˆé¦–æ¬¡å¯èƒ½éœ€è¦ 30-60 ç§’ï¼‰...")
            response = requests.post(
                f"{self.base_url}/api/generate",
                json=payload,
                timeout=90  # å»¶é•·è¶…æ™‚æ™‚é–“
            )
            
            if response.status_code == 200:
                data = response.json()
                result = data.get("response", "")
                print(f"   âœ… æ¨ç†æˆåŠŸ! å›æ‡‰: {result.strip()}")
                return True
            else:
                print(f"   âŒ æ¨ç†å¤±æ•— (HTTP {response.status_code})")
                print(f"   éŒ¯èª¤: {response.text}")
                return False
                
        except requests.exceptions.Timeout:
            print("   âŒ æ¨ç†è¶…æ™‚ï¼ˆ90ç§’ï¼‰")
            print("   å¯èƒ½åŸå› :")
            print("      1. VRAM ä¸è¶³ï¼Œæ¨¡å‹è¼‰å…¥åˆ°ç³»çµ±è¨˜æ†¶é«”")
            print("      2. å…¶ä»–ç¨‹å¼ä½”ç”¨éå¤š VRAM")
            print("      3. æ¨¡å‹æå£ï¼Œéœ€é‡æ–°ä¸‹è¼‰")
            return False
        except Exception as e:
            print(f"   âŒ éŒ¯èª¤: {e}")
            return False
    
    def get_gpu_info(self) -> None:
        """å˜—è©¦å–å¾— GPU è³‡è¨Š"""
        print("\nğŸ® GPU ç‹€æ…‹:")
        try:
            # å˜—è©¦åŸ·è¡Œ nvidia-smi
            result = subprocess.run(
                ["nvidia-smi", "--query-gpu=name,memory.total,memory.used,memory.free", 
                 "--format=csv,noheader,nounits"],
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if result.returncode == 0:
                lines = result.stdout.strip().split("\n")
                for i, line in enumerate(lines):
                    parts = [p.strip() for p in line.split(",")]
                    if len(parts) >= 4:
                        name, total, used, free = parts[:4]
                        used_pct = (float(used) / float(total)) * 100
                        print(f"   GPU {i}: {name}")
                        print(f"   ç¸½ VRAM: {total} MB | å·²ç”¨: {used} MB ({used_pct:.1f}%) | å¯ç”¨: {free} MB")
            else:
                print("   âš ï¸  ç„¡æ³•å–å¾— GPU è³‡è¨Šï¼ˆnvidia-smi ä¸å¯ç”¨ï¼‰")
        except FileNotFoundError:
            print("   âš ï¸  nvidia-smi æœªå®‰è£æˆ–ä¸åœ¨ PATH ä¸­")
        except Exception as e:
            print(f"   âš ï¸  ç„¡æ³•å–å¾— GPU è³‡è¨Š: {e}")
    
    def run_full_diagnostics(self) -> None:
        """åŸ·è¡Œå®Œæ•´è¨ºæ–·"""
        print("=" * 60)
        print("ğŸ”§ Moondream è¨ºæ–·å·¥å…·")
        print("=" * 60)
        
        # 1. æª¢æŸ¥æœå‹™
        if not self.check_server_status():
            return
        
        # 2. åˆ—å‡ºæ¨¡å‹
        models = self.list_installed_models()
        
        # 3. æª¢æŸ¥é‹è¡Œä¸­æ¨¡å‹
        running = self.check_running_models()
        
        # 4. æª¢æŸ¥ Moondream
        moondream_installed = self.check_moondream_installation(models)
        
        # 5. GPU è³‡è¨Š
        self.get_gpu_info()
        
        # 6. æ¨ç†æ¸¬è©¦ï¼ˆåƒ…ç•¶ Moondream å·²å®‰è£ï¼‰
        if moondream_installed:
            self.test_moondream_inference()
        
        print("\n" + "=" * 60)
        print("ğŸ“‹ è¨ºæ–·å®Œæˆ")
        print("=" * 60)


if __name__ == "__main__":
    diagnostics = OllamaDiagnostics()
    diagnostics.run_full_diagnostics()
